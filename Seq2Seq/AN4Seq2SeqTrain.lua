local Seq2Seq = require('Seq2Seq')
local AudioData = require('AudioData')
local Shuffler = require('Shuffler')
local an4FolderDir = "/root/CTCSpeechRecognition/Audio/an4"

-- Creates a deep copy of the given table.
function deepcopy(orig)
    local orig_type = type(orig)
    local copy
    if orig_type == 'table' then
        copy = {}
        for orig_key, orig_value in next, orig, nil do
            copy[deepcopy(orig_key)] = deepcopy(orig_value)
        end
        setmetatable(copy, deepcopy(getmetatable(orig)))
    else -- number, string, boolean, etc
    copy = orig
    end
    return copy
end

local random = 1 -- The higher the value, the more iterations of shuffling will happen per sentence.

local trainingTranscriptsTargets = AudioData.retrieveAN4TranscriptSet(an4FolderDir)
local shuffledTrainingTranscripts = Shuffler.shuffleSentences(deepcopy(trainingTranscriptsTargets), random)

local params = {
    learningRate = 0.001,
    iterations = 20000,
    vocabSize = 29,
    seqlen = 3,
    nbOfHiddenLayers = 2, -- The number of hidden layers of LSTMs excluding the encoder-decoder layers.
    hiddenLayerSize = 256, -- Size of hidden layers of LSTMs (including encoder-decoder layers).
    maxLabelSize = 20 -- The maximum characters if end label not generated by decoder.
}
local labels = {
    startLabel = 28,
    endLabel = 29
}

Seq2Seq:init(params)


-- Create the dataset and put them into tensors.
local dataset = {}

local encoderInputs = {}
for index, cleanSentence in ipairs(trainingTranscriptsTargets) do
    table.insert(encoderInputs, torch.Tensor(cleanSentence):cuda())
end

local decoderInputs = {}
local decoderTargets = {}

for index, shuffledSentence in ipairs(shuffledTrainingTranscripts) do
    local decoderInput = deepcopy(shuffledSentence)
    table.insert(decoderInput, 1, labels.startLabel)
    table.insert(decoderInputs, torch.Tensor(decoderInput):cuda())

    local decoderTarget = deepcopy(shuffledSentence)
    table.insert(decoderTarget, labels.endLabel)
    table.insert(decoderTargets, torch.Tensor(decoderTarget):cuda())
end

local pointer = 1
function dataset:nextData()
    pointer = pointer + 1
    if (pointer == #encoderInputs) then pointer = 1 end
    return encoderInputs[pointer], decoderInputs[pointer], decoderTargets[pointer]
end


Seq2Seq:trainNetwork(dataset)
local numberOfTestSamples = 5
for i = 1, numberOfTestSamples do
    local predictedLabels = Seq2Seq:predictNetwork(encoderInputs[i], labels)
    local sentence = ""
    for index, label in ipairs(predictedLabels) do
        sentence = sentence .. Shuffler.findLetter(label)
    end
    print(sentence)
end
Seq2Seq:createLossGraph()